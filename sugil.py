import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ìˆ˜ê¸¸ì´ - ìˆ˜í•™ì˜ ê¸¸ì¡ì´", 
    page_icon="ğŸ“",
    layout="centered"
)

# --- 2. ë””ìì¸(CSS) ---
st.markdown("""
<style>
    .stChatMessage { font-family: 'Pretendard', sans-serif; }
    h1 { color: #2E86C1; }
    .stButton button { border-radius: 20px; }
    
    [data-testid="stFileUploaderDropzoneInstructions"] > div > span { display: none; }
    [data-testid="stFileUploaderDropzoneInstructions"] > div > small { display: none; }
    [data-testid="stFileUploaderDropzoneInstructions"] > div::before {
        content: "ì—¬ê¸°ë¥¼ í´ë¦­í•´ì„œ ë¬¸ì œ/í’€ì´ ì‚¬ì§„ì„ ì˜¬ë¦¬ì„¸ìš”";
        display: block; font-weight: bold; font-size: 14px; color: #333; margin-bottom: 8px;
    }
    [data-testid="stFileUploaderDropzoneInstructions"] > div::after {
        content: "JPG, PNG, WEBP ì§€ì› (ìµœëŒ€ 200MB)";
        display: block; font-size: 11px; color: #888; margin-top: 8px;
    }
    [data-testid="stFileUploaderDropzone"] button { position: relative; color: transparent !important; }
    [data-testid="stFileUploaderDropzone"] button::after {
        content: "íŒŒì¼ ì°¾ê¸°"; color: #333; position: absolute; left: 50%; top: 50%;
        transform: translate(-50%, -50%); font-size: 14px; font-weight: normal; white-space: nowrap;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì • ë° ë„êµ¬")
    
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        api_key = st.text_input("ğŸ”‘ API Key ì…ë ¥", type="password")
        if not api_key:
            st.info("API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ìˆ˜ê¸¸ì´ê°€ ì‘ë™í•©ë‹ˆë‹¤.")
    
    st.divider()

    st.subheader("ğŸ“ í•™ìŠµ ëª¨ë“œ")
    teaching_mode = st.radio(
        "ìˆ˜ê¸¸ì´ì˜ ì—­í• :",
        ("ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜", "ğŸ•µï¸â€â™€ï¸ ê¼¼ê¼¼í•œ ì²¨ì‚­ ì½”ì¹˜"),
        index=0
    )
    
    coach_option = "ê¸°ë³¸"
    if teaching_mode == "ğŸ•µï¸â€â™€ï¸ ê¼¼ê¼¼í•œ ì²¨ì‚­ ì½”ì¹˜":
        st.caption("ğŸ§ ì½”ì¹­ ìŠ¤íƒ€ì¼")
        coach_option = st.radio(
            "ì½”ì¹­ ìŠ¤íƒ€ì¼ ì„ íƒ:",
            ("ğŸ’¡ íŒíŠ¸ ë° ì˜¤ë‹µ ì²´í¬", "ğŸ“š ê´€ë ¨ ê°œë…/ì›ë¦¬ ì„¤ëª…"),
            index=0,
            label_visibility="collapsed"
        )
    
    st.markdown("---")

    # í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ (ë¹„ìƒìš©)
    st.subheader("ğŸš€ ì—”ì§„ ì„¤ì •")
    use_advanced_model = st.toggle("ğŸ†˜ ê³ ë‚œë„ í‚¬ëŸ¬ ë¬¸í•­ (Gemini)", value=False)
    
    if use_advanced_model:
        st.error("ğŸ’ **Gemini 2.0 Flash ê°€ë™**\ní•˜ë£¨ ì‚¬ìš©ëŸ‰ì´ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì–´ë ¤ìš´ ë¬¸ì œì—ë§Œ ì“°ì„¸ìš”!")
    else:
        st.success("ğŸ€ **Gemma 3 (ê¸°ë³¸)**\në¬´ì œí•œ ë¬´ë£Œì…ë‹ˆë‹¤. ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë©ë‹ˆë‹¤!")

    st.divider()
    
    if st.button("ğŸ§¹ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°", use_container_width=True):
        st.session_state["messages"] = []
        st.rerun()

# --- 4. ë©”ì¸ í™”ë©´ ---
st.title("ğŸ§‘â€ğŸ« ìˆ˜ê¸¸ì´: ìˆ˜í•™ì˜ ê¸¸ì¡ì´")

if teaching_mode == "ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜":
    mode_msg = "ë¬¸ì œë¥¼ ì£¼ì‹œë©´ **ì •ë‹µê³¼ í’€ì´ ê³¼ì •**ì„ ì¹œì ˆí•˜ê²Œ ì•Œë ¤ë“œë ¤ìš”!"
elif coach_option == "ğŸ’¡ íŒíŠ¸ ë° ì˜¤ë‹µ ì²´í¬":
    mode_msg = "í‘¼ ì‹ì„ ë³´ì—¬ì£¼ì„¸ìš”. ì •ë‹µ ëŒ€ì‹  **í‹€ë¦° ë¶€ë¶„ê³¼ íŒíŠ¸**ë§Œ ì§šì–´ë“œë¦´ê²Œìš”."
else:
    mode_msg = "ë¬¸ì œ í’€ì´ë³´ë‹¤ëŠ” **í•µì‹¬ ìˆ˜í•™ ê°œë…ê³¼ ê³µì‹** ìœ„ì£¼ë¡œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”."

model_status = "Gemini 2.0 (ê³ ì„±ëŠ¥)" if use_advanced_model else "Gemma 3 (ë¬´ì œí•œ)"
with st.expander(f"ğŸ“˜ í˜„ì¬ ì„¤ì •: {teaching_mode} / {model_status}"):
    st.write(mode_msg)
    if not use_advanced_model:
        st.caption("ğŸ’¡ íŒ: í”„ë¡¬í”„íŠ¸ê°€ ê°•í™”ë˜ì—ˆì§€ë§Œ, ê·¸ë˜ë„ í‹€ë¦¬ë©´ 'ğŸ†˜ ê³ ë‚œë„'ë¥¼ ì¼œë³´ì„¸ìš”.")

# --- 5. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„) ---
# [ë³€ê²½ 1] ì¸íŠ¸ë¡œ ê¸ˆì§€ ëª…ë ¹ ì¶”ê°€
# [ë³€ê²½ 2] ì‚¬ê³  ê³¼ì •(CoT) ê°•ì œ ì£¼ì…
base_instruction = """
[Persona]
ë‹¹ì‹ ì€ ìˆ˜í•™ êµìœ¡ì„ ì „ê³µí•œ ëŒ€í•™ìƒ ë©˜í†  'ìˆ˜ê¸¸ì´'ì…ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ê²©ë ¤í•˜ëŠ” ì–´ì¡°(í•´ìš”ì²´)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

[âš ï¸ Critical Rules - MUST FOLLOW]
1. **No Intro:** ë‹µë³€ ì‹œì‘ ì‹œ "ì•ˆë…•í•˜ì„¸ìš”, ìˆ˜ê¸¸ì´ì…ë‹ˆë‹¤" ê°™ì€ ìê¸°ì†Œê°œë¥¼ **ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”.** ë°”ë¡œ ë³¸ë¡ (í’€ì´/ë‹µë³€)ìœ¼ë¡œ ë“¤ì–´ê°€ì„¸ìš”.
2. **Negative Logic Check:** ë¬¸ì œì— "ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤", "ì•„ë‹ˆë‹¤", "ì‹¤ê·¼ì´ ì—†ë‹¤" ê°™ì€ **ë¶€ì • ì¡°ê±´**ì´ ìˆë‹¤ë©´, ì´ë¥¼ ê°€ì¥ ë¨¼ì € ì¸ì‹í•˜ê³  í’€ì´ì— ë°˜ì˜í•˜ì„¸ìš”. (ë°˜ëŒ€ë¡œ í•´ì„í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.)
3. **Reasoning Process:** ì§ê´€ì ìœ¼ë¡œ ë‹µì„ ë‚´ì§€ ë§ê³ , **'ì¡°ê±´ ë¶„ì„ -> ê°œë… ì ìš© -> ë‹¨ê³„ë³„ í’€ì´ -> ê²€ì¦'**ì˜ ìˆœì„œë¥¼ ì§€í‚¤ì„¸ìš”.
4. **LaTeX:** ìˆ˜ì‹ì€ ë°˜ë“œì‹œ LaTeX($$) ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.
"""

# ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸ ìƒì„¸
prompt_solver = base_instruction + """
**[Mode: Solver]**
1. **Step-by-step:** ë…¼ë¦¬ì  ë¹„ì•½ ì—†ì´ ë‹¨ê³„ë³„ë¡œ ìƒì„¸íˆ í’€ì´í•˜ì„¸ìš”.
2. **Answer:** ìµœì¢… ì •ë‹µì„ ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.
3. **Example:** ë‹µë³€ ëì— ìœ ì‚¬ ë¬¸ì œ(Example)ë¥¼ í•˜ë‚˜ ì œì•ˆí•˜ì„¸ìš”.
"""

prompt_coach_hint = base_instruction + """
**[Mode: Hint Coach]**
1. **No Answer:** **ì ˆëŒ€ ì •ë‹µì´ë‚˜ ì „ì²´ í’€ì´ë¥¼ ë¨¼ì € ì•Œë ¤ì£¼ì§€ ë§ˆì„¸ìš”.**
2. **Find Error:** ì‚¬ìš©ìì˜ í’€ì´ì—ì„œ ì˜¤ë¥˜ë‚˜ ë…¼ë¦¬ì  í—ˆì ì„ ì°¾ì•„ ì§ˆë¬¸í˜• íŒíŠ¸ë¥¼ ì£¼ì„¸ìš”.
3. **Guide:** "ì´ ë¶€ë¶„ ë¶€í˜¸ë¥¼ ë‹¤ì‹œ ë³¼ê¹Œìš”?" ì²˜ëŸ¼ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê²Œ ìœ ë„í•˜ì„¸ìš”.
"""

prompt_coach_concept = base_instruction + """
**[Mode: Concept Coach]**
1. **Concept Focus:** ë¬¸ì œ í’€ì´ë³´ë‹¤ëŠ” **'í•µì‹¬ ì›ë¦¬'ì™€ 'ê³µì‹'** ì„¤ëª…ì— ì§‘ì¤‘í•˜ì„¸ìš”.
2. **Application:** ì •ë‹µì„ ë°”ë¡œ ì£¼ì§€ ë§ê³ , ê°œë…ì„ ì´í•´í•œ ë’¤ ë‹¤ì‹œ í’€ë„ë¡ ê²©ë ¤í•˜ì„¸ìš”.
"""

# í”„ë¡¬í”„íŠ¸ ì„ íƒ
if teaching_mode == "ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜":
    current_system_prompt = prompt_solver
else:
    if coach_option == "ğŸ“š ê´€ë ¨ ê°œë…/ì›ë¦¬ ì„¤ëª…":
        current_system_prompt = prompt_coach_concept
    else:
        current_system_prompt = prompt_coach_hint

# --- 6. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

uploaded_file = st.sidebar.file_uploader("ğŸ“¸ ë¬¸ì œ ì‚¬ì§„", type=["jpg", "png", "jpeg", "webp"])

# --- 7. ì‹¤í–‰ ë° ëª¨ë¸ í˜¸ì¶œ ---
if prompt := st.chat_input("ì§ˆë¬¸í•˜ê±°ë‚˜, ë‚´ê°€ í‘¼ ì‹ì„ ì ì–´ë³´ì„¸ìš”..."):
    if not api_key:
        st.error("âš ï¸ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        st.stop()

    genai.configure(api_key=api_key)

    st.chat_message("user").markdown(prompt)
    image_input = None
    if uploaded_file:
        image_input = Image.open(uploaded_file)
        with st.chat_message("user"):
            st.image(image_input, width=300)
            
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ëª¨ë¸ í˜¸ì¶œ ë¡œì§
    if use_advanced_model:
        model_name = "gemini-2.0-flash" 
        model = genai.GenerativeModel(model_name=model_name, system_instruction=current_system_prompt)
        final_prompt = [prompt, image_input] if image_input else prompt
    else:
        model_name = "gemma-3-27b-it"
        model = genai.GenerativeModel(model_name=model_name)
        # Gemmaì—ê²Œ ê°•ë ¥í•œ í”„ë¡¬í”„íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì£¼ì…
        combined_text = current_system_prompt + "\n\n[User Question]: " + prompt
        final_prompt = [combined_text, image_input] if image_input else combined_text

    # ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        loading_text = "ğŸ’ Geminiê°€ ê¹Šê²Œ ê³ ë¯¼ ì¤‘..." if use_advanced_model else "ğŸ€ ìˆ˜ê¸¸ì´ê°€ í’€ì´ ì¤‘..."
        
        with st.spinner(loading_text):
            try:
                response = model.generate_content(final_prompt, stream=True)
                for chunk in response:
                    try:
                        if chunk.text:
                            full_response += chunk.text
                            message_placeholder.markdown(full_response + "â–Œ")
                    except: pass
                
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                if "429" in str(e):
                    st.error("ğŸš¨ ì‚¬ìš©ëŸ‰ ì´ˆê³¼! ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                else:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
