import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. ë””ìì¸ ë° ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="ìˆ˜ê¸¸ì´ - ìˆ˜í•™ì˜ ê¸¸ì¡ì´", 
    page_icon="ğŸ“",
    layout="centered"
)

# --- 2. ì»¤ìŠ¤í…€ CSS (ë””ìì¸ ë””í…Œì¼) ---
st.markdown("""
<style>
    .stChatMessage { font-family: 'Pretendard', sans-serif; }
    h1 { color: #2E86C1; }
    .stButton button { border-radius: 20px; }

    /* ì—…ë¡œë” ë””ìì¸ ìˆ˜ì • (í•œê¸€í™”) */
    [data-testid="stFileUploaderDropzoneInstructions"] > div > span { display: none; }
    [data-testid="stFileUploaderDropzoneInstructions"] > div > small { display: none; }
    [data-testid="stFileUploaderDropzoneInstructions"] > div::before {
        content: "ì—¬ê¸°ë¥¼ í´ë¦­í•´ì„œ ë¬¸ì œ ë˜ëŠ” í’€ì´ ì‚¬ì§„ì„ ì˜¬ë¦¬ì„¸ìš”";
        display: block;
        font-weight: bold;
        font-size: 14px;
        color: #333;
        margin-bottom: 8px;
    }
    [data-testid="stFileUploaderDropzoneInstructions"] > div::after {
        content: "JPG, PNG, WEBP (ìµœëŒ€ 200MB)";
        display: block;
        font-size: 11px;
        color: #888;
        margin-top: 8px;
    }
    [data-testid="stFileUploaderDropzone"] button {
        position: relative;
        color: transparent !important;
    }
    [data-testid="stFileUploaderDropzone"] button::after {
        content: "íŒŒì¼ ì°¾ê¸°";
        color: #333;
        position: absolute;
        left: 50%; top: 50%;
        transform: translate(-50%, -50%);
        font-size: 14px;
        font-weight: normal;
        white-space: nowrap;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. ì‚¬ì´ë“œë°” (ì„¤ì • ë° ë„êµ¬) ---
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì • ë° ë„êµ¬")
    
    # API í‚¤ ì²˜ë¦¬
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        api_key = st.text_input("ğŸ”‘ API Key ì…ë ¥", type="password")
        if not api_key:
            st.info("API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ìˆ˜ê¸¸ì´ê°€ ì‘ë™í•©ë‹ˆë‹¤.")
    
    st.divider()

    # [í•µì‹¬] ëª¨ë“œ ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€
    st.subheader("ğŸ“ í•™ìŠµ ëª¨ë“œ ì„ íƒ")
    teaching_mode = st.radio(
        "ìˆ˜ê¸¸ì´ì˜ êµìœ¡ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:",
        ("ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜", "ğŸ•µï¸â€â™€ï¸ ê¼¼ê¼¼í•œ ì²¨ì‚­ ì½”ì¹˜"),
        index=0,
        help="í’€ì´ ì„ ìƒë‹˜: ì •ë‹µê³¼ ê³¼ì •ì„ ì•Œë ¤ì¤ë‹ˆë‹¤.\nì²¨ì‚­ ì½”ì¹˜: í‹€ë¦° ê³³ë§Œ ì°¾ì•„ì„œ íŒíŠ¸ë¥¼ ì¤ë‹ˆë‹¤."
    )
    
    st.divider()
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ§¹ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°", use_container_width=True):
        st.session_state["messages"] = []
        st.rerun()

# --- 4. ë©”ì¸ í™”ë©´ ---
st.title("ğŸ§‘â€ğŸ« ìˆ˜ê¸¸ì´: ìˆ˜í•™ì˜ ê¸¸ì¡ì´")

# ëª¨ë“œì— ë”°ë¥¸ ì•ˆë‚´ ë¬¸êµ¬ ë³€ê²½
if teaching_mode == "ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜":
    mode_guide = "ë¬¸ì œë¥¼ ë³´ì—¬ì£¼ì‹œë©´ **ë‹¨ê³„ë³„ í’€ì´ì™€ ì •ë‹µ**ì„ ì¹œì ˆí•˜ê²Œ ì•Œë ¤ë“œë ¤ìš”!"
else:
    mode_guide = "ë³¸ì¸ì´ í‘¼ ì‹ì„ ë³´ì—¬ì£¼ì„¸ìš”. **ì •ë‹µ ëŒ€ì‹  í‹€ë¦° ë¶€ë¶„**ì„ ì°¾ì•„ë“œë¦´ê²Œìš”!"

with st.expander(f"ğŸ“˜ í˜„ì¬ ëª¨ë“œ: {teaching_mode} (í´ë¦­í•´ì„œ ì„¤ëª… ë³´ê¸°)"):
    st.info(mode_guide)

# --- 5. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (ëª¨ë“œë³„ ë¶„ê¸°) ---

# ê³µí†µ ê¸°ë³¸ ì„¤ì •
base_instruction = """
ë‹¹ì‹ ì€ ìˆ˜í•™ êµìœ¡ì„ ì „ê³µí•œ ëŒ€í•™ìƒ ë©˜í†  'ìˆ˜ê¸¸ì´'ì…ë‹ˆë‹¤.
ì˜¤ì§ ìˆ˜í•™/ê³¼í•™ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ë©°, ìˆ˜ì‹ì€ LaTeX($$)ë¥¼ ì‚¬ìš©í•´ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ê²©ë ¤í•˜ëŠ” ì–´ì¡°(í•´ìš”ì²´)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""

# ëª¨ë“œ 1: í’€ì´ ëª¨ë“œ (ê¸°ì¡´)
prompt_solver = base_instruction + """
**[Mode: Solver & Explainer]**
1. ì‚¬ìš©ìê°€ ë¬¸ì œë¥¼ ì œì‹œí•˜ë©´ **ë‹¨ê³„ë³„(Step-by-step)ë¡œ ë…¼ë¦¬ì ì¸ í’€ì´ ê³¼ì •**ì„ ì œì‹œí•˜ì„¸ìš”.
2. ìµœì¢…ì ìœ¼ë¡œ **ì •ë‹µ**ì„ ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.
3. ë‹µë³€ ëì—ëŠ” í•™ìŠµìì˜ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ ë¹„ìŠ·í•œ ìœ í˜•ì˜ **ìœ ì‚¬ ë¬¸ì œ(Example)**ë¥¼ í•˜ë‚˜ ì œì•ˆí•˜ì„¸ìš”.
"""

# ëª¨ë“œ 2: ì²¨ì‚­ ëª¨ë“œ (ì‹ ê·œ)
prompt_coach = base_instruction + """
**[Mode: Error Checker & Coach]**
1. **ì ˆëŒ€ ë¨¼ì € ì •ë‹µì´ë‚˜ ì „ì²´ í’€ì´ë¥¼ ì•Œë ¤ì£¼ì§€ ë§ˆì„¸ìš”.** (ê°€ì¥ ì¤‘ìš”)
2. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì‹ì´ë‚˜ í’€ì´ ê³¼ì •(ì´ë¯¸ì§€/í…ìŠ¤íŠ¸)ì„ ë¶„ì„í•˜ì—¬ **ì˜¤ë¥˜(Error)ë‚˜ ë…¼ë¦¬ì  í—ˆì **ì„ ì°¾ì•„ë‚´ì„¸ìš”.
3. "ì´ ë¶€ë¶„ì—ì„œ ë¶€í˜¸ê°€ í‹€ë¦° ê²ƒ ê°™ì•„ìš”", "ì—¬ê¸°ì„œëŠ” ì–´ë–¤ ê³µì‹ì„ ì¨ì•¼ í• ê¹Œìš”?"ì™€ ê°™ì´ **ì§ˆë¬¸ê³¼ íŒíŠ¸**ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ ê¹¨ë‹«ê²Œ ìœ ë„í•˜ì„¸ìš”.
4. ë§Œì•½ ì‚¬ìš©ìê°€ í’€ì´ ì—†ì´ ë¬¸ì œë§Œ ì¤¬ë‹¤ë©´, "ë¨¼ì € ì–´ë–»ê²Œ í’€ì—ˆëŠ”ì§€ ì‹ì„ ë³´ì—¬ì£¼ì‹œê² ì–´ìš”?"ë¼ê³  ì—­ìœ¼ë¡œ ì§ˆë¬¸í•˜ì—¬ ì°¸ì—¬ë¥¼ ìœ ë„í•˜ì„¸ìš”.
5. í•™ìƒì´ ê°œë…ì„ í—·ê°ˆë ¤í•˜ë©´ ê·¸ **ê°œë…ì— ëŒ€í•´ì„œë§Œ** ì„¤ëª…í•´ì£¼ê³ , ë‹¤ì‹œ ë¬¸ì œë¡œ ëŒì•„ì™€ ìŠ¤ìŠ¤ë¡œ í’€ê²Œ í•˜ì„¸ìš”.
"""

# í˜„ì¬ ì„ íƒëœ ëª¨ë“œì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ í™•ì •
current_system_prompt = prompt_solver if teaching_mode == "ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜" else prompt_coach

# --- 6. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# --- 7. ì±„íŒ… ë‚´ìš© í‘œì‹œ ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì´ë¯¸ì§€ ì—…ë¡œë”
uploaded_file = st.sidebar.file_uploader("ğŸ“¸ ë¬¸ì œ/í’€ì´ ì‚¬ì§„ ì—…ë¡œë“œ", type=["jpg", "png", "jpeg", "webp"])

# --- 8. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
if prompt := st.chat_input("ì§ˆë¬¸í•˜ê±°ë‚˜, ë‚´ê°€ í‘¼ ì‹ì„ ì ì–´ë³´ì„¸ìš”..."):
    if not api_key:
        st.error("âš ï¸ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        st.stop()

    genai.configure(api_key=api_key)

    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬
    image_input = None
    if uploaded_file:
        image_input = Image.open(uploaded_file)
        with st.chat_message("user"):
            st.image(image_input, width=300)
            
    st.session_state.messages.append({"role": "user", "content": prompt})

    # --- 9. Gemma 3 í˜¸ì¶œ ---
    model = genai.GenerativeModel(model_name="gemma-3-27b-it")

    # í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ (ì„ íƒëœ ëª¨ë“œì˜ í”„ë¡¬í”„íŠ¸ ì ìš©)
    combined_text = current_system_prompt + "\n\n[User Question]: " + prompt
    
    if image_input:
        final_prompt = [combined_text, image_input]
    else:
        final_prompt = combined_text

    # --- 10. AI ì‘ë‹µ ìƒì„± ---
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # ìŠ¤í”¼ë„ˆ ë©˜íŠ¸ë„ ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥´ê²Œ!
        loading_msg = "ìˆ˜ê¸¸ì´ê°€ í’€ì´í•˜ëŠ” ì¤‘... ğŸ§ " if teaching_mode == "ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜" else "ìˆ˜ê¸¸ì´ê°€ í’€ì´ë¥¼ ê²€í† í•˜ëŠ” ì¤‘... ğŸ§"

        with st.spinner(loading_msg):
            try:
                response = model.generate_content(final_prompt, stream=True)
                
                for chunk in response:
                    try:
                        if chunk.text:
                            full_response += chunk.text
                            message_placeholder.markdown(full_response + "â–Œ")
                    except Exception:
                        pass 
                
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                st.error("ì•—, ìˆ˜ê¸¸ì´ê°€ ì ì‹œ ìƒê°ì„ ë©ˆì·„ì–´ìš”. (ìƒˆë¡œê³ ì¹¨ í•˜ê±°ë‚˜ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”)")
