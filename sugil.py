import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. ê¸°ë³¸ í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ìˆ˜ê¸¸ì´ - ìˆ˜í•™ì˜ ê¸¸ì¡ì´", page_icon="ğŸ“")
st.title("ğŸ§‘â€ğŸ« ìˆ˜ê¸¸ì´: ìˆ˜í•™ì˜ ê¸¸ì¡ì´")

# --- 2. API í‚¤ ì„¤ì • (secrets.toml ìš°ì„ , ì—†ìœ¼ë©´ ì‚¬ì´ë“œë°” ì…ë ¥) ---
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = st.sidebar.text_input("Google AI Studio API Key", type="password")

# --- 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìˆ˜ê¸¸ì´ì˜ í˜ë¥´ì†Œë‚˜ ì„¤ì •ê°’) ---
# ì´ ë‚´ìš©ì€ ë³€ìˆ˜ì— ë‹´ì•„ë‘ê³  ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì£¼ì…í•©ë‹ˆë‹¤.
system_prompt_text = """
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì‹¤ë ¥ ìˆëŠ” ìˆ˜í•™ íŠœí„° 'ìˆ˜ê¸¸ì´'ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì›ì¹™ì„ ì§€ì¼œ ë‹µë³€í•˜ì„¸ìš”:
1. LaTeX ìˆ˜ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš” (ì˜ˆ: $x^2 + 2x$).
2. í’€ì´ëŠ” ë‹¨ê³„ë³„(Step-by-step)ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
3. ì„¤ëª… ëì—ëŠ” "ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ ìœ ì‚¬í•œ ë¬¸ì œë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤."ë¼ë©° ì˜ˆì œë¥¼ í•˜ë‚˜ ì œì‹œí•˜ì„¸ìš”.
4. í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ê²©ë ¤í•˜ëŠ” ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""

# --- 4. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡) ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# --- 5. ì±„íŒ… í™”ë©´ êµ¬í˜„ ---
# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ì´ë“œë°” ì´ë¯¸ì§€ ì—…ë¡œë”
uploaded_file = st.sidebar.file_uploader("ë¬¸ì œ ì‚¬ì§„ ì—…ë¡œë“œ", type=["jpg", "png", "jpeg", "webp"])

# --- 6. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ì‚¬ì§„ì„ ì˜¬ë¦¬ê³  'í’€ì–´ì¤˜'ë¼ê³  í•˜ì„¸ìš”."):
    if not api_key:
        st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ê±°ë‚˜ secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    genai.configure(api_key=api_key)

    # ì‚¬ìš©ì ë©”ì‹œì§€ UI í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    image_input = None
    if uploaded_file:
        image_input = Image.open(uploaded_file)
        with st.chat_message("user"):
            st.image(image_input, width=200)
            
    # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})

    # --- [í•µì‹¬] ëª¨ë¸ ì„ íƒ ë° í”„ë¡¬í”„íŠ¸ êµ¬ì„± ---
    if uploaded_file:
        # [ìƒí™© A] ì‚¬ì§„ì´ ìˆìŒ -> ëˆˆì´ ë‹¬ë¦° Gemini ì‚¬ìš© (í•˜ë£¨ 20íšŒ ì œí•œ)
        selected_model = "gemini-2.5-flash-lite"
        
        # GeminiëŠ” ì •ì„ëŒ€ë¡œ system_instruction íŒŒë¼ë¯¸í„° ì‚¬ìš©
        model = genai.GenerativeModel(
            model_name=selected_model,
            system_instruction=system_prompt_text 
        )
        final_prompt = [prompt, image_input] # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ
        
    else:
        # [ìƒí™© B] ì‚¬ì§„ ì—†ìŒ -> ì‚¬ìš©ëŸ‰ì´ ë„‰ë„‰í•œ Gemma ì‚¬ìš© (ë¬´ì œí•œê¸‰)
        selected_model = "gemma-3-27b-it"
        
        # GemmaëŠ” system_instructionì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¹„ì›Œë‘¡ë‹ˆë‹¤.
        model = genai.GenerativeModel(
            model_name=selected_model
        )
        
        # ëŒ€ì‹  ì§ˆë¬¸ ë§¨ ì•ì— í˜ë¥´ì†Œë‚˜ ì„¤ì •ì„ ë¶™ì—¬ì„œ ë³´ëƒ…ë‹ˆë‹¤.
        final_prompt = system_prompt_text + "\n\nì‚¬ìš©ì ì§ˆë¬¸: " + prompt

    # --- 7. AI ì‘ë‹µ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° ---
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # 1. ëª¨ë¸ë³„ í˜¸ì¶œ ë°©ì‹ êµ¬ë¶„
            if selected_model == "gemma-3-27b-it":
                # Gemma: ì±„íŒ… ê¸°ë¡(History) ì—†ì´ í˜„ì¬ ì§ˆë¬¸ì— ì§‘ì¤‘ (ì˜¤ë¥˜ ìµœì†Œí™”)
                response = model.generate_content(final_prompt, stream=True)
            else:
                # Gemini: ì´ì „ ëŒ€í™” ê¸°ë¡(History) í¬í•¨í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€
                chat_history = []
                for msg in st.session_state.messages[:-1]:
                    role = "user" if msg["role"] == "user" else "model"
                    chat_history.append({"role": role, "parts": [msg["content"]]})
                
                chat = model.start_chat(history=chat_history)
                response = chat.send_message(final_prompt, stream=True)
            
            # 2. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ (ì—¬ê¸°ì— ì˜¤ë¥˜ ìˆ˜ì • ë¡œì§ ì ìš©ë¨!)
            for chunk in response:
                try:
                    # chunk.textì— ì ‘ê·¼í•  ë•Œ 'ë¹ˆ ìƒì(ì¢…ë£Œ ì‹ í˜¸)'ë©´ ì—ëŸ¬ê°€ ë‚˜ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                except Exception:
                    # ë§ˆì§€ë§‰ ì¡°ê°(finish_reason=1)ì´ë¼ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë¬´ì‹œí•˜ê³  ë„˜ì–´ê°
                    pass
            
            # 3. ìµœì¢… ë‹µë³€ í‘œì‹œ
            message_placeholder.markdown(full_response)
            
            # 4. ê¸°ë¡ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            # ì—ëŸ¬ ë©”ì‹œì§€ ì¹œì ˆí•˜ê²Œ ë³´ì—¬ì£¼ê¸°
            if "400" in str(e):
                st.error(f"ìš”ì²­ í˜•ì‹ ì˜¤ë¥˜ (400): {e}")
            elif "404" in str(e):
                st.error(f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {selected_model}")
            elif "429" in str(e):
                st.error("ğŸ”’ ë¬´ë£Œ ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. (ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”)")
            elif "Image" in str(e) or "multimodal" in str(e):
                st.error("í˜„ì¬ ëª¨ë¸(Gemma)ì€ ì´ë¯¸ì§€ë¥¼ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Gemini ì „í™˜ ì‹¤íŒ¨)")
            else:
                st.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
