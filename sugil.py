import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. ë””ìì¸ ë° ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ìˆ˜ê¸¸ì´ - ìˆ˜í•™ì˜ ê¸¸ì¡ì´", page_icon="ğŸ“", layout="centered")

# --- 2. ì»¤ìŠ¤í…€ CSS ---
st.markdown("""
<style>
    .stChatMessage { font-family: 'Pretendard', sans-serif; }
    h1 { color: #2E86C1; }
    .stButton button { border-radius: 20px; }
    [data-testid="stFileUploaderDropzoneInstructions"] > div > span { display: none; }
    [data-testid="stFileUploaderDropzoneInstructions"] > div > small { display: none; }
    [data-testid="stFileUploaderDropzoneInstructions"] > div::before {
        content: "ì—¬ê¸°ë¥¼ í´ë¦­í•´ì„œ ë¬¸ì œ/í’€ì´ ì‚¬ì§„ì„ ì˜¬ë¦¬ì„¸ìš”";
        display: block; font-weight: bold; font-size: 14px; color: #333; margin-bottom: 8px;
    }
    [data-testid="stFileUploaderDropzoneInstructions"] > div::after {
        content: "JPG, PNG, WEBP (ìµœëŒ€ 200MB)";
        display: block; font-size: 11px; color: #888; margin-top: 8px;
    }
    [data-testid="stFileUploaderDropzone"] button { position: relative; color: transparent !important; }
    [data-testid="stFileUploaderDropzone"] button::after {
        content: "íŒŒì¼ ì°¾ê¸°"; color: #333; position: absolute; left: 50%; top: 50%;
        transform: translate(-50%, -50%); font-size: 14px; font-weight: normal; white-space: nowrap;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì • ë° ë„êµ¬")
    
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        api_key = st.text_input("ğŸ”‘ API Key ì…ë ¥", type="password")
        if not api_key:
            st.info("API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ìˆ˜ê¸¸ì´ê°€ ì‘ë™í•©ë‹ˆë‹¤.")
    
    st.divider()

    st.subheader("ğŸ“ í•™ìŠµ ëª¨ë“œ")
    teaching_mode = st.radio("ì—­í•  ì„ íƒ:", ("ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜", "ğŸ•µï¸â€â™€ï¸ ê¼¼ê¼¼í•œ ì²¨ì‚­ ì½”ì¹˜"), index=0)
    
    coach_option = "ê¸°ë³¸"
    if teaching_mode == "ğŸ•µï¸â€â™€ï¸ ê¼¼ê¼¼í•œ ì²¨ì‚­ ì½”ì¹˜":
        st.caption("ğŸ§ ì½”ì¹­ ë°©ì‹")
        coach_option = st.radio("ì½”ì¹­ ë°©ì‹:", ("ğŸ’¡ íŒíŠ¸ ë° ì˜¤ë‹µ ì²´í¬", "ğŸ“š ê´€ë ¨ ê°œë…/ì›ë¦¬ ì„¤ëª…"), index=0, label_visibility="collapsed")
    
    st.markdown("---")

    st.subheader("ğŸ§ª ì—”ì§„ ì‹¤í—˜ì‹¤")
    # ì—¬ê¸°ê°€ í•µì‹¬ì…ë‹ˆë‹¤! ì„ ìƒë‹˜ì´ ë°œê²¬í•œ ëª¨ë¸ë¡œ êµì²´!
    use_advanced_model = st.toggle("ğŸ’ íˆë“  ëª¨ë¸ (Gemini 2.5)", value=False)
    
    if use_advanced_model:
        st.success("ğŸ§ª **ì‹¤í—˜ ëª¨ë“œ ê°€ë™!**\nGemini 2.5 Audio-Dialog ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    else:
        st.info("ğŸ€ **ê¸°ë³¸ ëª¨ë“œ (Gemma 3)**\nì•ˆì •ì ì´ê³  ë¬´ì œí•œì…ë‹ˆë‹¤.")

    st.divider()
    if st.button("ğŸ§¹ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°", use_container_width=True):
        st.session_state["messages"] = []
        st.rerun()

# --- 4. ë©”ì¸ í™”ë©´ ---
st.title("ğŸ§‘â€ğŸ« ìˆ˜ê¸¸ì´: ìˆ˜í•™ì˜ ê¸¸ì¡ì´")

# í”„ë¡¬í”„íŠ¸ ì„¤ì • (ê³µí†µ)
base_instruction = """
ë‹¹ì‹ ì€ ìˆ˜í•™ êµìœ¡ì„ ì „ê³µí•œ ëŒ€í•™ìƒ ë©˜í†  'ìˆ˜ê¸¸ì´'ì…ë‹ˆë‹¤.
ì˜¤ì§ ìˆ˜í•™/ê³¼í•™ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ë©°, ìˆ˜ì‹ì€ LaTeX($$)ë¥¼ ì‚¬ìš©í•´ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ê²©ë ¤í•˜ëŠ” ì–´ì¡°(í•´ìš”ì²´)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

[âš ï¸ í•„ìˆ˜ ë…¼ë¦¬ ì ê²€ ì‚¬í•­]
1. ë¶€ì • ì¡°ê±´("ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤", "ì•„ë‹ˆë‹¤")ì„ ì£¼ì˜ ê¹Šê²Œ í•´ì„í•˜ì„¸ìš”.
2. ê·¸ë˜í”„ ê°œí˜•ì´ë‚˜ íŠ¹ìˆ˜ì„±ì„ í•¨ë¶€ë¡œ ê°€ì •í•˜ì§€ ë§ˆì„¸ìš”.
"""

prompt_solver = base_instruction + """
**[Mode: Solver & Explainer]**
1. ë‹¨ê³„ë³„(Step-by-step)ë¡œ ë…¼ë¦¬ì ì¸ í’€ì´ ê³¼ì •ì„ ì œì‹œí•˜ì„¸ìš”.
2. ìµœì¢… ì •ë‹µì„ ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.
3. ë‹µë³€ ëì— ìœ ì‚¬ ë¬¸ì œ(Example)ë¥¼ í•˜ë‚˜ ì œì•ˆí•˜ì„¸ìš”.
"""

prompt_coach_hint = base_instruction + """
**[Mode: Error Checker & Hint Giver]**
1. **ì ˆëŒ€ ì •ë‹µì„ ë¨¼ì € ì•Œë ¤ì£¼ì§€ ë§ˆì„¸ìš”.**
2. ì‚¬ìš©ìì˜ í’€ì´ì—ì„œ ì˜¤ë¥˜ë‚˜ ë…¼ë¦¬ì  ë¹„ì•½ì„ ì°¾ì•„ ì§ˆë¬¸í˜• íŒíŠ¸ë¥¼ ì£¼ì„¸ìš”.
"""

prompt_coach_concept = base_instruction + """
**[Mode: Concept Explainer]**
1. ë¬¸ì œ í’€ì´ë³´ë‹¤ëŠ” 'ì›ë¦¬'ì™€ 'í•µì‹¬ ê³µì‹' ì„¤ëª…ì— ì§‘ì¤‘í•˜ì„¸ìš”.
"""

if teaching_mode == "ğŸŒŸ ì¹œì ˆí•œ í’€ì´ ì„ ìƒë‹˜":
    current_system_prompt = prompt_solver
else:
    if coach_option == "ğŸ“š ê´€ë ¨ ê°œë…/ì›ë¦¬ ì„¤ëª…":
        current_system_prompt = prompt_coach_concept
    else:
        current_system_prompt = prompt_coach_hint

# --- 5. ì„¸ì…˜ ë° ì±„íŒ… í‘œì‹œ ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

uploaded_file = st.sidebar.file_uploader("ğŸ“¸ ë¬¸ì œ/í’€ì´ ì‚¬ì§„ ì—…ë¡œë“œ", type=["jpg", "png", "jpeg", "webp"])

# --- 6. ì…ë ¥ ì²˜ë¦¬ ë° ëª¨ë¸ í˜¸ì¶œ ---
if prompt := st.chat_input("ì§ˆë¬¸í•˜ê±°ë‚˜, ë‚´ê°€ í‘¼ ì‹ì„ ì ì–´ë³´ì„¸ìš”..."):
    if not api_key:
        st.error("âš ï¸ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        st.stop()

    genai.configure(api_key=api_key)

    st.chat_message("user").markdown(prompt)
    image_input = None
    if uploaded_file:
        image_input = Image.open(uploaded_file)
        with st.chat_message("user"):
            st.image(image_input, width=300)
            
    st.session_state.messages.append({"role": "user", "content": prompt})

    # --- [ëŒ€ë§ì˜ ëª¨ë¸ í˜¸ì¶œë¶€] ---
    try:
        if use_advanced_model:
            # ğŸš€ ì„ ìƒë‹˜ì´ ë°œê²¬í•˜ì‹  íˆë“  ëª¨ë¸!
            # (ë§Œì•½ ì´ ì´ë¦„ì´ ì½”ë“œì—ì„œ ì¸ì‹ ì•ˆ ë˜ë©´ 404 ì˜¤ë¥˜ê°€ ëœ° ìˆ˜ ìˆìŠµë‹ˆë‹¤)
            model_name = "gemini-2.5-flash-native-audio-dialog"
            
            # ì˜¤ë””ì˜¤ ëª¨ë¸ì´ë¼ system instructionì´ ì˜ ì•ˆ ë¨¹í ìˆ˜ë„ ìˆì§€ë§Œ ì¼ë‹¨ ì‹œë„
            model = genai.GenerativeModel(
                model_name=model_name,
                system_instruction=current_system_prompt
            )
        else:
            # ğŸ€ ë“ ë“ í•œ êµ­ë°¥ Gemma
            model_name = "gemma-3-27b-it"
            model = genai.GenerativeModel(model_name=model_name)
            # GemmaëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í…ìŠ¤íŠ¸ì— í•©ì¹˜ê¸°
            prompt = current_system_prompt + "\n\n[Question]: " + prompt

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if image_input:
            final_prompt = [prompt, image_input]
        else:
            final_prompt = prompt

        # --- ì‘ë‹µ ìƒì„± ---
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            # ëª¨ë¸ ì´ë¦„ í‘œì‹œ (ë””ë²„ê¹…ìš©)
            spinner_text = f"ğŸ§ª ì‹¤í—˜ì²´({model_name}) ê°€ë™ ì¤‘..." if use_advanced_model else "ğŸ€ ìˆ˜ê¸¸ì´(Gemma)ê°€ í’€ì´ ì¤‘..."

            with st.spinner(spinner_text):
                response = model.generate_content(final_prompt, stream=True)

                for chunk in response:
                    try:
                        if chunk.text:
                            full_response += chunk.text
                            message_placeholder.markdown(full_response + "â–Œ")
                    except Exception:
                        pass 
                
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ë©”ì‹œì§€ ì¶œë ¥
        if "404" in str(e):
            st.error(f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ëŒ€ìš”: {model_name}")
            st.info("ì´ ëª¨ë¸ì€ ì•„ì§ APIë¡œ ê³µê°œë˜ì§€ ì•Šì•˜ê±°ë‚˜, ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif "400" in str(e):
            st.error(f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
            st.info("ì˜¤ë””ì˜¤ ëª¨ë¸ì´ë¼ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì…ë ¥ì„ ê±°ë¶€í–ˆì„ ìˆ˜ë„ ìˆì–´ìš”.")
        else:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.write("ì ì‹œ ë„ê³  Gemma ëª¨ë“œë¡œ ëŒì•„ê°€ì£¼ì„¸ìš” ğŸ˜­")
